<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <!-- Open Graph meta tags (Facebook/LinkedIn) -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="Enhancing Jailbreak Attacks via Compliance-Refusal-Based Initialization"/>
  <meta property="og:description" content="Demonstration of CRI for gradient-based jailbreak attacks on LLMs."/>
  <meta property="og:url" content="URL_OF_THE_WEBSITE"/>
  <meta property="og:image" content="static/images/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <!-- No Twitter meta tags included -->

  <!-- Keywords for indexing -->
  <meta name="keywords" content="Jailbreak Attacks, Compliance Refusal Initialization, GCG, LLM, CRI, HarmBench">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Enhancing Jailbreak Attacks via Compliance-Refusal-Based Initialization</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <!-- Bulma and custom CSS -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <!-- JS scripts -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <!-- Hero / Title Section -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              Jailbreak Attack Initializations as Extractors of Compliance Directions
            </h1>

            <!-- Authors -->
        <!-- Authors -->
        <div class="is-size-5 publication-authors" style="margin-top: 1.5em;">
          <div class="author-block">
            <strong>Amit LeVi</strong><sup>*1</sup>,  
            <strong>Rom Himelstein</strong><sup>*2</sup>,  
            <a href="https://scholar.google.com/citations?hl=en&user=Tzi_svcAAAAJ" target="_blank">Yaniv Nemcovsky</a><sup>*1</sup>, 
            <a href="https://scholar.google.com/citations?hl=en&user=PiREobkAAAAJ" target="_blank">Avi Mendelson</a><sup>1</sup>, 
            <a href="https://scholar.google.com/citations?hl=en&user=lfWCxJYAAAAJ" target="_blank">Chaim Baskin</a><sup>3</sup>
          </div>
        </div>


            <!-- Affiliations -->
            <div class="is-size-6 publication-authors" style="margin-top: 1em;">
              <p>
                <sup>1</sup>Department of Computer Science, Technion - Israel Institute of Technology<br>
                <sup>2</sup>Department of Data and Decision Science, Technion - Israel Institute of Technology<br>
                <sup>3</sup>School of Electrical and Computer Engineering, Ben-Gurion University of the Negev
              </p>
              <p class="eql-cntrb" style="margin-top: 1em;">
                <small><sup>*</sup>Indicates Equal Contribution</small>
              </p>
            </div>
            
            <div class="author-emails" style="margin-top: 0.5em;">
              <a href="mailto:amitlevi@campus.technion.ac.il" target="_blank">amitlevi@campus.technion.ac.il</a>, 
              <a href="mailto:romh@campus.technion.ac.il" target="_blank">romh@campus.technion.ac.il</a>
            </div>

            <!-- Links (ArXiv, GitHub, etc.) -->
            <div class="publication-links" style="margin-top: 1.5em;">
              <span class="link-block">
                <a href="https://arxiv.org/abs/2502.09755" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/wr0om/Compliance-Refusal-Initialization" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Code</span>
                </a>
              </span>
            </div>
          </div> <!-- column -->
        </div> <!-- columns -->
    </div> <!-- hero-body -->
  </section>

  <!-- Paper abstract -->
  <section class="section hero is-light">
      <div class="container is-max-desktop">
          <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                  <h2 class="title is-3">Abstract</h2>
                  <div class="content has-text-justified">
                      <p>
                          Safety-aligned LLMs respond to prompts with either compliance or refusal, each corresponding to distinct directions in the modelâ€™s activation space.
                          Recent works show that initializing attacks via self-transfer from other prompts significantly enhances their performance.
                          However, the underlying mechanisms of these initializations remain unclear, and attacks utilize arbitrary or hand-picked initializations.
                          This work presents that each gradient-based jailbreak attack and subsequent initialization gradually converge to a single compliance direction that suppresses refusal, thereby enabling an efficient transition from refusal to compliance.
                          Based on this insight, we propose CRI, an initialization framework that aims to project unseen prompts further along compliance directions.
                          We demonstrate our approach on multiple attacks, models, and datasets, achieving an increased attack success rate (ASR) and reduced computational overhead, highlighting the fragility of safety-aligned LLMs.
                      </p>
                  </div>
              </div>
          </div>
      </div>
  </section>
  <!-- End paper abstract -->
  
    
  
  
    <!-- Image carousel -->
  <section class="hero is-small">
      <div class="hero-body">
          <div class="container">
              <div class="carousel results-carousel" id="results-carousel">
                  <div class="item" style="text-align: center;">
                      <!-- Your image here -->
                      <img alt="Motivation" src="static/images/nips_harmful_prompt_embeddings.jpg"/>
                      <h2 class="subtitle has-text-centered">
                          Visualization of our initialization strategy.
                      </h2>
                  </div>
                  <div class="item" style="text-align: center;">
                      <!-- Your image here -->
                      <img alt="LFS" src="static/images/LFS.jpg"/>
                      <h2 class="subtitle has-text-centered">
                          Empirical evaluation of our framework's initialization choice.
                      </h2>
                  </div>
                   <div class="item" style="text-align: center;">
                      <!-- Your image here -->
                      <img alt="ASR" src="static/images/advbench_llama2_ASR.jpg"/>
                      <h2 class="subtitle has-text-centered">
                          Empirical evaluation of our framework's success.
                      </h2>
                  </div>
                
                
              </div>
          </div>
      </div>
  </section>
  <!-- End image carousel -->
  
  <!-- BibTeX citation (Optional) -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
<pre><code>@misc{levi2025enhancingjailbreakattackscompliancerefusalbased,
      title={Enhancing Jailbreak Attacks via Compliance-Refusal-Based Initialization}, 
      author={Amit Levi and Rom Himelstein and Yaniv Nemcovsky and Avi Mendelson and Chaim Baskin},
      year={2025},
      eprint={2502.09755},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2502.09755}, 
}
</code></pre>
    </div>
  </section>

  <!-- Footer -->
  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the 
              <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">
                Academic Project Page Template
              </a> 
              which was adopted from the 
              <a href="https://nerfies.github.io" target="_blank">Nerfies</a> 
              project page. You are free to borrow the source code of this website; we just ask that you link back 
              to this page in the footer. <br>
              This website is licensed under a 
              <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">
                Creative Commons Attribution-ShareAlike 4.0 International License
              </a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- (Optional) Analytics scripts can go here -->

</body>
</html>


